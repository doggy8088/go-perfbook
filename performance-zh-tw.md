# 撰寫和優化 Go 程式碼

本文件概述撰寫高效能 Go 程式碼的最佳實踐。

雖然有些討論會提高單個服務的速度（透過快取等），但設計高效能的分散式系統已經超出了這份文件的範圍。在監控和分散式系統設計方面已經有很好的文章，它包含了一套完全不同的研究和設計權衡理論。

本文所有內容將依據 [CC-BY-SA](https://creativecommons.org/licenses/by-sa/3.0/tw/) 授權發行。

本書區分以下不同章節：

1. 撰寫高效能軟體的基本技巧

   - 說明 "[CS101](https://web.stanford.edu/class/cs101/) 等級" 的東西

2. 撰寫高效軟體的技巧

   - 描述所有與 Go 相關的主題，告訴你如何從 Go 擷取最好的語言特性

3. 撰寫**真正**高效軟體的進階技巧

   - 當你優化過的程式碼還不夠快時可以參考

我們可以總結成以下三個部分：

- "合理的" ("Be reasonable")
- "慎重的" ("Be deliberate")
- "危險的" ("Be dangerous")

## 何時何地做優化 (When and Where to Optimize)

我先把這個放在第一位，是因為這真的是最重要的一步。你曾經也應該這樣做嗎？

每個優化都有成本。通常，這個成本是用程式碼複雜度或認知負載來表示的 -- 優化後的程式碼很少比未優化的版本簡單。

但另一方面，我將稱之為「優化經濟學」。作為程式設計師，你的時間是寶貴的。你可以為你的專案工作的機會成本，哪些錯誤需要修復，以及需要新增哪些功能。優化的工作是很有趣的，但並不總是正確的選擇。效能是一項功能，但代價和正確性也是如此。

選擇最重要的工作。有時它不是一個實際的CPU優化，而是一個使用者體驗。就像新增進度條一樣簡單，或者透過在渲染頁面後在後台執行計算來提高頁面的響應速度。

有時這是顯而易見的：在三小時內完成的報告在一小時完成可能不太有用。

僅僅因為容易優化並不意味著它是值得優化的。忽略沒有價值的優化，是一種合理的開發策略。

把這看作是優化**你的**時間。

你必須選擇什麼要優化，以及何時優化，你可以在「高效軟體」和「快速部署」之間調整比例。

人們無意識地重複說名言——「過早的優化是萬惡之源」，但他們錯過了它的主要內容。

> 〝程式設計師浪費了大量的時間來思考或者擔心程式中非關鍵部分的速度，而這些效率的嘗試實際上在考慮除錯和維護時會產生很大的負面影響。我們應該忘記那些微小的效能改進，他可能會花上我們 97％ 的開發時間：過早的優化是萬惡之源，但我們不應該放棄這關鍵的 3％ 優化機會。〞
> -- <cite>Knuth</cite>

[Scott Meyers](https://www.aristeia.com/) 的 [DConf 2017 Day 2 Keynote: Things that Matter](https://www.youtube.com/watch?time_continue=429&v=3WBaY61c9sE) 影片中提到：

- 不要忽視簡單的優化
- 培養更多演算法和資料結構的相關知識，可以讓你實作優化的過程變得「更容易」或「更明顯」

你應該優化嗎？

> 是的，但是只有當問題很重要時，程式真的太慢了，並且能夠在維持正確性、穩定性和程式可讀性的同時變得更快。
> -- The Practice of Programming, Kernighan and Pike

過早優化 (Premature optimization) 會把你綁在特定決策模式，進而傷害軟體的可維護性。優化過的代碼通常會讓需求發生改變時更難修改，如果需要丟棄時，也會更難痛下決心丟棄不用(沉默成本謬誤)。

[BitFunnel 效能評估](http://bitfunnel.org/strangeloop) 有一些數字可以使這種權衡更加明確。想象一下假設搜尋引擎需要跨越多個數據中心的 30,000 台機器，這些機器每年的成本約為 1,000 美元。如果你可以將軟體的速度提高一倍，這可以為公司節省每年 1,500 萬美元。即便一個開發人員花費整整一年時間將效能提高 1％ 左右，所賺回的成本也能完全支付開發人員一年的薪水！

在絕大多數情況下，程式的大小和速度不是問題。最簡單的優化通常都不用做些什麼。第二簡單的優化技巧，就是購買更快的硬體。

如果你決定要改變你的程式，請繼續看下去。

## 如何優化

### 優化工作流程

在介紹具體細節之前，我們先談談優化的一般過程。

優化是一種重構。但是，每一步不是改進原始碼的某些方面（程式碼重複，清晰度等），而是可以提高效能的某些方面：降低 CPU、記憶體使用率、降低延遲等。這種改進通常以可讀性為代價。這意味著除了一套全面的單元測試（以確保你的更改沒有破壞任何內容）之外，你還需要一套很好的效能測試(benchmarks)，以確保您的更改對效能產生預期的影響。你必須能夠驗證您的更改是否真的在降低 CPU。有時候你認為會改善效能的變化實際上會變成零或負變化。在這些情況下，務必確保撤消修改的程式。

<cite>[What is the best comment in source code you have ever encountered? - Stack Overflow](https://stackoverflow.com/questions/184618/what-is-the-best-comment-in-source-code-you-have-ever-encountered)</cite>:

```js
//
// Dear maintainer:
//
// Once you are done trying to 'optimize' this routine,
// and have realized what a terrible mistake that was,
// please increment the following counter as a warning
// to the next guy:
//
// total_hours_wasted_here = 42
//
```

你使用的效能測試(benchmarks)必須正確，並為代表性工作負載提供可重複的數字。如果單個的執行差異太大，則會使得小的改進更難以發現。你將需要使用[benchstat](https://golang.org/x/perf/benchstat)或等效的統計測試，而不能只是用眼睛去看(請注意，使用統計測試無論如何都是一個好主意)。應該記錄執行效能測試(benchmarks)的步驟，並且應該向儲存函式庫提交任何自訂指令碼和工具，並提供如何執行它們的說明。要注意需要很長時間才能執行的大型效能測試(benchmarks)套件：它會使開發迭代變慢。

還要注意，任何可以測量的東西都可以優化。確保你正在衡量正確的事情。

下一步是決定你正在優化什麼。如果目標是改進CPU，那麼什麼是可接受的速度。你想要將當前的效能提高2倍嗎？10倍？你能否說它是「小於時間T的大小為N的問題」？你想減少記憶體使用量嗎？多少錢？對於記憶體使用情況的變化，可以接受的速度有多慢？你願意放棄什麼來換取較低的空間需求？

優化服務延遲是一個棘手的問題。整本書都是關於如何對Web伺服器進行效能測試的。主要問題是：對於單個函式，對於給定的問題規模，效能相當一致。對於webservices，你沒有一個單一的效能數字。一個適當的Web服務基準套件將為給定的需求/秒級別提供延遲分佈。這篇演講很好地概述了Gil Tene的一些問題：["如何不去測量延遲" by Gil Tene](https://youtu.be/lJ8ydIuPFeU)

TODO：請參閱後面的關於優化Web服務的部分

績效目標必須具體。你會（幾乎）總是能夠更快地做出一些事情。優化往往是一個收益遞減的遊戲。你需要知道何時停止。你要付出多少努力才能完成最後一點工作。你願意做出這樣的程式碼是多麼難以維護？

Dan Luu之前提到的[BitFunnel效能評估](http://bitfunnel.org/strangeloop)的演講顯示了一個使用粗略計算來確定目標效能資料是否合理的例子。

TODO：程式設計珠璣有「Fermi Problems」。從Jeff Dean's 幻燈片可以瞭解

對於綠地開發，你不應該把所有的基準和效能數字都留到最後。很容易說「我們稍後會修復」，但如果效能非常重要，那麼從一開始就將是一個設計考慮因素。在解決效能問題時所需的任何重大體系結構更改在截止日期前將過於冒險。請注意，在開發過程中，重點應放在合理的程式設計，算​​法和資料結構上。在更低層次的堆疊優化應該等到開發週期晚些時候才能獲得更完整的系統性能檢視。你在系統不完整時執行的任何完整系統配置檔案都會對完成系統中瓶頸的位置給出偏斜檢視。

TODO：如何避免/發現軟體寫得不好的情況下的「凌遲」。

作為CI的一部分，效能測試(benchmarks)是很難的，因為嘈雜的因素，甚至不同的CI盒子，那麼很難獲取效能指標。一個好的基礎是讓開發人員執行效能測試(benchmarks)（在適當的硬體上）並將其包含在提交訊息中，專門用於處理效能問題。對於那些只是提普通補丁的人來說，儘量在程式碼審查中捕捉效能下降。

TODO：如何追蹤一段時間的效能表現？

撰寫你可以測試的程式碼。你可以在較大的系統上執行分析。你可以透過效能測試(benchmarks)測試孤立的部分。你需要能夠提取並設定足夠的環境上下文，以便效能測試(benchmarks)足夠並具有代表性。

你的目標是什麼和目前的表現之間的差異也會讓你知道從哪裡開始。如果你只需要10％-20％的效能改進，那麼可以透過一些實作調整和較小的修復來實現。如果你需要一個10倍或更多的因子，那麼用一個左移代替一個乘法不會削減它。這可能會要求你的堆疊上下進行更改。

良好的效能工作需要從系統設計，網路，硬體(CPU，快取，儲存)，演算法，調整和除錯等多個不同層面的知識。在時間和資源有限的情況下，考慮哪個級別能夠提供最大的改進：它並不總是演算法或程式調優。

一般而言，優化應該從上到下進行。系統級別的優化將比表達級別的影響更大。確保你在適當的水平上解決問題。

本書主要討論如何減少CPU使用率，減少記憶體使用量並減少延遲。很高興指出你很少能做到這三點。也許CPU時間更快，但現在你的程式使用更多的記憶體。也許你需要減少記憶體空間，但現在該程式需要更長的時間。

[阿姆達爾定律](https://en.wikipedia.org/wiki/Amdahl%27s_law)告訴我們要關注瓶頸。如果你將執行時間僅佔5％的例程速度提高一倍，那麼整個掛鐘的速度只有2.5％。另一方面，將80％的時間加速10％的例程將使執行時間提高近8％。配置檔案將有助於確定實際花費的時間。

優化時，你想減少CPU必須完成的工作量。Quicksort比氣泡排序更快，因為它能以更少的步驟解決相同的問題(排序)。這是一個更高效的演算法。你已經減少了CPU完成相同任務所需完成的工作。

像編譯器優化一樣，程式調優通常只會在整個執行時間中造成一點小小的負擔。大的勝利幾乎總是來自演算法改變或資料結構的改變，這是你的程式組織方式的根本轉變。編譯器技術有所改進，但速度很慢。Proebsting定律表明，編譯器每18 年的效能翻倍，這與摩爾定律(稍微誤解了解釋)形成鮮明對比，該定律使處理器效能每18 個月翻一番。演算法改進在更大的範圍內工作。從1991年到2008年，混合器整數規劃演算法提高了30,000倍 有關更具體的示例，請考慮[此故障](https://medium.com/@buckhx/unwinding-uber-s-most-efficient-service-406413c5871d)取代優步部落格文章中描述的蠻力地理空間演算法，使用更適合於所提交任務的更專業的演算法。沒有編譯器開關可以提供相同的效能提升。

TODO：在gttse07.pdf中優化浮點FFT和MMM演算法的差異

分析器可能會告訴你，大量的時間都花在了特定的例程上。這可能是一個昂貴的例程，或者它可能是一個便宜的例程，只是被呼叫許多次。你可以先看看是否可以減少呼叫的次數或完全不呼叫，而不是立即嘗試優化這個例程。我們將在下一節討論更具體的優化策略。

三個優化問題：

- 我們必須這樣做嗎？最快的程式碼是永遠不會執行的程式碼。
- 如果是的話，這是最好的演算法。
- 如果是的話，這是這個演算法的最佳實現。

## 具體的優化技巧

Jon Bentley在1982年的作品「撰寫高效程式」將程式優化視為一個工程問題：基準。分析。提高。校驗。迭代。他的一些技巧現在由編譯器自動完成。程式設計師的工作是使用編譯器無法做到的轉換。

本書的摘要如下：

- <http://www.crowl.org/lawrence/programming/Bentley82.html>
- <http://www.geoffprewett.com/BookReviews/WritingEfficientPrograms.html>

和程式調整規則：
<https://web.archive.org/web/20080513070949/http://www.cs.bell-labs.com/cm/cs/pearls/apprules.html>

在考慮對程式進行更改時，有兩個基本選項：你可以更改資料，也可以更改程式碼。

### 資料的更改

改變你的資料意味著增加或改變你正在處理的資料的表示。從效能角度來看，其中一些最終會改變與資料結構的不同方面相關的O()。

增加資料結構的想法：

- 額外欄位：例如，儲存連結列表的大小，而不是在詢問時迭代。或者將經常需要的其他節點的指標儲存到多個搜尋中(例如，雙向連結列表中的「向後」連結以進行刪除O(1))。當你需要的資料便於儲存並保持最新時，這些更改很有用。

- 額外的搜尋索引：大多數資料結構都是為單一型別的查詢而設計的。如果你需要兩種不同的查詢型別，對資料進行額外的「檢視」可能會有很大的改進。例如，[] struct，由ID參考，但有時是string - > map [string] id(或- struct)

- 有關元素的額外資訊：例如布隆過濾器。這些資料結構必須小而快，以免壓倒其餘的資料結構。

- 如果查詢很昂貴，請新增一個快取。我們都熟悉memcache，但還有程序內快取。
- 透過網路，網路+序列化成本將會受到影響
- 程序內快取，但現在你需要擔心到期
- 即使是單個專案也可以幫助(日誌檔案時間解析示例)

當這些資料的儲存成本低、容易維持更新版本時，這些改變是相當有用的。

在資料結構的層面來說，這些都是「做更少」的明確範例，他們都會佔用空間，而且大部分情況下，當你對 CPU 進行優化時，你的程式都會用到更多記憶體。這就是經典的「拿空間換時間」([space-time trade-off](https://en.wikipedia.org/wiki/Space%E2%80%93time_tradeoff))。

如果你的程式使用太多的記憶體，也可以換個方式。減少空間使用量以換取更多計算。而不是儲存的東西，每次計算它們。你還可以壓縮記憶體中的資料，並在需要時隨時對其進行解壓縮。

[記憶體受限系統](https://gamehacking.org/faqs/Small_Memory_Software.pdf)是一本網上可獲取的書籍，涵蓋了減少程式使用記憶體空間的技術。雖然它最初是針對嵌入式開發人員撰寫的，但這些想法適用於處理大量資料的現代硬體的程式。

- 重新排列你的資料

    消除結構填充。刪除額外的欄位。使用較小的資料型別

- 更改為較慢的資料結構

    較簡單的資料結構通常具有較低的記憶體要求。例如，從一個指標重的樹結構轉向使用切片和線性搜尋。

- 為你的資料客製化壓縮格式

    []位元組（snappy，gzip，lz4），浮點數（go-tsz），整數（delta，xor + huffman）大量的壓縮資源。你需要檢查資料還是可以保持壓縮？你需要隨機訪問還是只有流媒體？壓縮具有額外索引的塊。如果不是在程序中，而是寫入磁碟，那麼遷移或新增/刪除欄位呢？你現在正在處理raw []位元組而不是很好的結構化Go型別。

我們稍後會詳細討論資料佈局。

現代計算機和儲存器層次結構使空間/時間的權衡不太明確。查詢表很容易在記憶體中「遠離」(因此訪問成本很高)，使得每次需要時重新計算一次值都會更快。

這也意味著效能測試(benchmarks)通常會顯示由於快取爭用而導致生產系統無法實現的改進(例如，查詢表在效能測試(benchmarks)期間位於處理器快取中，但在真實系統中使用時總是會被「真實資料」沖刷。雜湊表實際上直接解決了這個問題，比較了滿足和無約束的處理器快取上的效能。參見[Jump Hash paper](https://arxiv.org/pdf/1406.2294.pdf)論文中的圖4和圖5。

TODO：如何模擬滿足的快取，顯示增量成本

另一個要考慮的方面是資料傳輸時間。通常，網路和磁碟訪問非常緩慢，因此能夠載入壓縮塊的速度將比獲取資料後解壓縮資料所需的額外CPU時間快得多。一如既往，基準。二進位制格式通常比文字格式更小且更快解析，但代價是不再是人類可讀的格式。

對於資料傳輸，轉移到一個不那麼有趣的協議，或者增加API以允許部分查詢。例如，增量查詢而不是每次都被迫獲取整個資料集。

## 演算法的更改

如果你不更改資料，另一個主要選項是更改程式碼。

最大的改進很可能來自演算法變化。這與使用快速排序將氣泡排序替換為從O(n ^ 2)排序到O(n log n)或使用對映查詢替換透過過去是小O(n)的陣列的線性掃描等效(O (1))。

最大的改進可能來自演算法變化。這相當於用quicksort（O(nlogn)）替換O(n^2)的氣泡排序或者透過雜湊查詢（O(1)）替換陣列（O(n)）的線性掃描。

這就是軟體如何變慢。最初設計用於一種用途的結構被重新用於未設計的東西。這是逐漸發生的。

直觀地掌握不同的大O級別是很重要的。為你的問題選擇正確的資料結構。你不必一直刮刮鬍鬚，但是這樣做可以防止很久以後才會發現的愚蠢的效能問題。

基本的複雜類別是：

- O（1）：欄位訪問，陣列或地圖查詢
建議：不要擔心

- O（log n）：二進位制搜尋
建議：如果處於迴圈狀態，則只是一個問題

- O（n）：簡單迴圈
建議：你一直在這樣做

- O（n log n）：分而治之，排序
建議：還是相當快的

- O（n - m）：巢狀迴圈/二次方
建議：小心並限制你的大小

- 二次和次指數之間的任何其他內容
建議：不要在一百萬行上執行

- O（b ^ n），O（n！）：指數上升
建議：如果你有十幾個或兩個資料點，祝您好運

連結：<http://bigocheatsheet.com>

假設你需要搜尋未分類的資料集。「我應該用二分搜尋」，你知道一個二分搜尋O(log n)比O(n)線性掃描快。但是，二分查詢需要對資料進行排序，這意味著你需要先對它進行排序，這將花費O(n log n)時間。如果你正在進行大量搜尋，那麼分類的前期成本將會得到回報。另一方面，如果你主要做查詢，也許有一個數組是錯誤的選擇，你最好支付O(1)查詢地圖的代價。

選擇最簡單的合理資料結構並繼續。這是用於撰寫「非慢速軟體」的CS 101。這應該是您的預設開發模式。如果您知道需要隨機訪問，請不要選擇連結列表。如果您知道需要按順序遍歷，請不要使用地圖。需求變化，你不能總是猜測未來。對工作量做出合理的猜測。

<http://daslab.seas.harvard.edu/rum-conjecture/>

類似問題的資料結構在做一件工作時會有所不同。隨著插入的發生，二叉樹每次排序一次。未排序的陣列插入速度更快但未排序：最後，「敲定」你需要一次完成排序。

當撰寫一個供其他人使用的套件時，避免每個用例都要優先考慮的誘惑。這將導致程式碼不可讀。按設計的資料結構實際上是單一用途的。你既不能讀懂頭腦，也不能預測未來。如果使用者說「你的軟體包對於這個用例太慢」，一個合理的答案可能是「然後在這裡使用這個軟體包」。一攬子計劃應該「做得很好」。

有時混合資料結構將提供你需要的效能改進。例如，透過分段資料，你可以將搜尋範圍限制在一個儲存桶中。這仍然支付O(n)的理論成本，但常數會更小。當我們進行程式設計調整時，我們將重新審視這些調整。

在討論大O符號時，人們忘記了兩件事

其一，涉及到一個不變的因素。具有相同演算法複雜度的兩種演算法可以具有不同的常數因子。想象一下，迴圈遍歷一個列表100次，而僅迴圈一次。即使兩者都是O（n），也有一個恆定的因子是100倍。

這些常數因素是為什麼即使合併排序，快速排序和排列所有O(n log n)，每個人都使用快速排序，因為它是最快的。它具有最小的常數因子。

第二件事是大O只說「隨著n增長到無窮大」。它談到了增長趨勢，「隨著數字變大，這是主導執行時間的增長因素。」 它沒有提到實際的表現，也沒有說明它如何表現小n。

經常有一個分界點，在這個分界點以下，木材演算法更快。Go標準函式庫sort套件的一個很好的例子。大多數時候它使用快速排序，但是當分區大小降到12個元素以下時，它會進行shell排序傳遞，然後進行插入排序。

對於某些演算法，常數因子可能非常大，以致此截點可能比所有合理的輸入都大。也就是說，O（n ^ 2）演算法對於所有可能處理的輸入都比O（n）演算法快。

這也是另一種方式：例如，即使小輸入的基準變慢，選擇使用更復雜的資料結構來給出O（n）縮放而不是O（n ^ 2）。這也適用於大多數無鎖資料結構。它們通常在單執行緒情況下較慢，但在多執行緒使用它時更具可擴充套件性。

現代計算機中的儲存器層次結構將問題混淆了一點，因為快取記憶體更喜歡將片段掃描到追蹤指標的有效隨機訪問的可預測訪問。不過，最好從一個好的演算法開始。我們將在硬體特定部分討論這個問題。

「這場鬥爭可能並不總是最強，也不是最快的比賽，但這是打賭的方式。」 - 吉卜林。

有時，針對特定問題的最佳演算法不是單一的演算法，而是專門針對稍微不同的輸入類別的演算法集合。這個「polyalgorithm」可以快速檢測出需要處理的輸入型別，然後傳送到相應的程式碼路徑。這就是上面提到的排序包所做的：確定問題的大小並選擇不同的演算法。除了結合quicksort，shell排序和插入排序之外，它還會追蹤快速排序的遞迴深度並在必要時呼叫堆排序。在string與bytes包做類似的事情，檢測和專門處理不同的情況。與資料壓縮一樣，您對輸入內容的瞭解越多，訂製解決方案就越好。即使優化並不總是適用，透過確定使用和執行不同的邏輯是安全的，使程式碼複雜化可能是值得的。

這也適用於你的演算法需要解決的子問題。例如，能夠使用基數排序可以對效能產生重大影響，如果只需要部分排序，則可以使用快速選擇。

有時候，而不是專門針對您的特定任務，最好的方法是將其抽象為研究人員已經充分研究的更一般的問題空間。然後，您可以將更一般的解決方案應用於您的特定問題。將你的問題對映到已經有很好研究實現的領域可能是一個重大的勝利。

## 基準輸入

瞭解你的每種輸入尺寸可能在生產中有多大。

你的效能測試(benchmarks)必須使用適當大小的輸入。正如我們所看到的，不同的演算法在不同的輸入大小下都有意義。如果你的預期輸入範圍<100，那麼你的基準應該反映這一點。否則，選擇最適合n = 10 ^ 6的演算法可能不是最快的。

能夠產生有代表性的測試資料。不同的資料分佈會在你的演算法中引發不同的行為：想想經典的「資料排序時快速排序為O(n ^ 2)」示例。類似地，對於均勻的隨機資料，插值搜尋是O(log log n)，但是O(n)最差的情況。知道你的輸入是什麼樣子是代表性基準和選擇最佳演算法的關鍵。如果你用來測試的資料不能代表實際工作負載，那麼你可以輕鬆完成針對某個特定資料集的優化，「過度配置」你的程式碼以便使用一組特定的輸入進行最佳工作。

這也意味著你的基準資料需要代表真實世界。如果重複的請求非常少見，保留它們比重新計算它們更昂貴。如果你的基準資料僅包含相同的重複請求，則快取將提供不準確的效能檢視。

另請注意，一旦部署到生產環境並且在40核心伺服器上達到25萬次/秒，膝上型電腦上可能看不到的一些問題就可以看到。

撰寫好的效能測試(benchmarks)可能很困難。
TODO：microbenchmarks顯示速度減慢但巨集觀（現實世界）效能提高的情況。

- <https://timharris.uk/misc/five-ways.pdf>

## 程式調整

程式調優曾經是一種藝術形式，但編譯器變得更好。所以現在事實證明，編譯器可以比複雜的程式碼更好地直接優化程式碼。Go編譯器在匹配gcc和clang方面還有很長的路要走，但這確實意味著在調整時需要小心，特別是在升級Go版本時不要變得更糟。一旦編譯器得到改進，肯定會出現一些針對缺少特定編譯器優化工作的調整。

TODO：<https://github.com/golang/go/commit/9eb219480e8de08d380ee052b7bff293856955f8>）

如果你正在解決特定的執行時或編譯器程式碼產生問題，請始終使用指向上游問題的連結記錄你的更改。這可以讓你在bug修復後快速重新訪問你的優化。

打擊基於民間傳說的崇拜「效能提示」的誘惑，甚至是從你自己的經驗中過度概括。每個效能缺陷都需要根據自身的優點加以處理。即使之前已經有效，確保配置檔案確保修復仍然適用。你以前的工作可以指導你，但不要盲目應用以前的優化。

程式調優是一個迭代過程。繼續重新訪問你的程式碼並檢視可以進行哪些更改。確保你在每一步都取得進展。經常有一項改進可以使其他人獲得成功。(現在我沒有做A，我可以透過做C來簡化B)。這意味著你需要繼續觀察整個圖片，而不是沉迷於一小組線。

一旦你確定了正確的演算法，程式調優就是改進演算法實現的過程。在Big-O表示法中，這是減少與程式相關的常量的過程。

所有程式的效能調教，不是將效能差的部分變快，就是讓效率差的部分減少執行次數。演算法的改變也屬於這部分，但我們會更專注在微小的改變。你的確切做法會隨著技術變化而有所不同。

做一個緩慢的事情可能會用更快的雜湊函式替換SHA1或者hash/fnv1。少做一次緩慢的事情可能會節省一個大檔案的雜湊計算結果，因此你不必多次執行該操作。

保留意見。如果不需要做什麼，請解釋原因。通常，在優化演算法時，你會發現在某些情況下不需要執行的步驟。記錄它們。其他人可能會認為這是一個錯誤，需要放回去。

空程式立刻給出了錯誤的答案。
如果你不必是正確的，那麼很快就會很快。

「正確性」可以取決於問題。啟發式演算法大多數情況下是正確的，大部分時間都可以很快，而且猜測和改進的演算法可以讓您在達到可接受的限制時停下來。

快取的常見情況：

- 你的快取甚至不需要很大。
- 參見下面的 time.Parse（）例子; 只有一個價值觀產生了影響
- 但要注意快取失效，執行緒問題等。
- 隨機快取驅逐是快速且足夠有效的。
- 隨機快取插入可以用最少的邏輯將快取限制為流行的專案。
- 將快取邏輯的成本與重新獲取資料的成本進行比較。
- 大型的快取物件可能會增加 GC 壓力。在極端的案例中(鮮少或從不清楚快取、快取所有執行成本高的函式)，這些都會進入**記憶化**([Memoization](https://en.wikipedia.org/wiki/Memoization))的情境。

我已經完成了一個網路追蹤實驗，表明即使是最佳的快取也不值得。你的預期命中率很重要。你需要將比率匯出到你的監控堆疊。不斷變化的比例將顯示流量的變化。然後是重新訪問快取大小或過期策略的時候了。

程式調優：

程式調優是以小步驟迭代改程序序的藝術。Egon Elbre列出了他的程式：

- 提出一個假設，為什麼你的程式很慢。
- 拿出N個解決方案來解決它
- 嘗試一切，並保持最快。
- 以防萬一。
- 重複。

調校可以採取多種形式。

- 如果可能，請保留舊的實現以進行測試。
- 如果不可能，則產生足夠的黃金測試用例來比較輸出。
- 「足夠」意味著包括極端案例(edge cases)，因為這些可能會受到調優的影響，因為您旨在提高一般情況下的效能。
- 利用數學的特性：
  - 注意：實作與優化數值計算幾乎是一個專門的領域
    - <https://github.com/golang/go/commit/ed6c6c9c11496ed8e458f6e0731103126ce60223>
    - <https://gist.github.com/dgryski/67e6a7ff94c3a1add30eb26ec0ad8b0f>
    - 與加法相乘
    - 使用 WolframAlpha，Maxima，sympy 和類似工具來專門化，優化或建立查詢表
    - （還有這份文件 👉 <https://users.ece.cmu.edu/~franzf/papers/gttse07.pdf>）
    - 從浮點數學到整數數學
    - 或者 mandelbrot 刪除 sqrt，或者 lttb 刪除 abs，`a < b/c` => `a - c < b`
    - 考慮不同的數值表示法：固定點數、浮點數、（更小的）整數
    - 愛好者：帶誤差累加器的整數（如 Bresenham 的線和圓），多基數/冗餘數值系統
  - 「只為你使用的東西付費，而不是你可以使用的東西」
    - zero only part of an array, rather than the whole thing
  - 從微小的調整開始，一次只調整幾個陳述式
  - 便宜的條件檢查優先於昂貴的條件檢查
    - 例如：採用 strcmp 優於 regexp ，（參見: bloom filter before query）、讓效率差的部分減少執行次數("do expensive things fewer times")
  - 先處理常見的案例，再處理罕見的案例。例如：避開永遠會失敗的測試案例
  - 展開仍然有效：<https://play.golang.org/p/6tnySwNxG6O>
    - 程式碼大小 與 各種判斷條件 的間接成本 (code size vs. branch test overhead)
  - 使用偏移(offsets)優於切片(slice)，這對進行邊界檢查有幫助，資料依賴性和程式碼產生器（少於在內部迴圈中複製）。
  - 移除迴圈中的 **邊界檢查**(bounds check) 與 **空值檢查**(nil checks): <https://go-review.googlesource.com/c/go/+/151158>
  - 其他可以證明有效的小技巧
  - this is where pieces of Hacker's Delight fall

許多針對調優的民間傳說效能提示依賴於對編譯器的優化不足，並鼓勵程式設計師手動完成這些轉換。編譯器一直在使用更新，而不是用15年的時間乘以或除以2的冪 - 現在沒有人應該親自去做。類似地，提升迴圈中的不變計算，基本迴圈展開，常見子表示式消除等等都是由gcc和clang等自動完成的。Go的編譯器完成了其中的許多工作，並繼續改進。一如往常，在提交新版本之前進行效能測試(benchmarks)。

編譯器無法做到的轉換依賴於你瞭解有關演算法，輸入資料，系統中的不變數以及可以做出的其他假設等事情，並將該隱式知識分解為刪除或更改資料結構中的步驟。

每個優化都會對你的資料進行假設。這些必須記錄下來，甚至更好地進行測試。這些假設將會在你的程式崩潰，放慢速度，或隨著系統發展而開始返回錯誤資料的地方。

程式調整改進是累積的。5倍3％的改善是15％的改善。進行優化時，值得考慮預期的效能改進。用更快的替換雜湊函式是一個不斷改進的因素。

瞭解你的要求和可以改變的地方可以提高效能。在#performance Gophers Slack頻道中呈現的一個問題是用於為字串鍵/值對對映建立唯一標識的花的數量。最初的解決方案是提取鍵，對它們進行排序，並將結果字串傳遞給雜湊函式。我們提出的改進解決方案是在鍵/值新增到地圖時對其進行單獨雜湊處理，然後將所有這些雜湊在一起以建立識別符號。

這是一個專業化的例子。

假設我們正在處理一天中的大量日誌檔案，並且每行都以時間戳開始。

Sun  4 Mar 2018 14：35：09 PST <...........................>
對於每行，我們呼叫time.Parse()把它變成一個格式。如果效能分析顯示我們time.Parse()是瓶頸，那麼我們有幾種方法可以加快速度。

最簡單的方法是保留先前看到的時間戳和相關曆元的單項快取。只要我們的日誌檔案在一秒鐘內有多行，這將是一場勝利。對於1000萬行日誌檔案的情況，這種策略將昂貴的呼叫數量time.Parse()從10,000,000減少到86400 - 每個獨立的秒鐘一個。

TODO：單項快取的程式碼示例

我們可以做更多嗎？因為我們確切知道時間戳的格式， 並且它們都在一天內完成，所以我們可以撰寫自訂時間解析邏輯，將其考慮在內。我們可以計算午夜的時代，然後從時間戳字串中提取小時，分鐘和秒 - 它們都將在字串中處於固定偏移量 - 並執行一些整數運算。

TODO：字串偏移版本的程式碼示例

在我的效能測試(benchmarks)中，這將解析時間從275ns / op減少到5ns / op。（當然，即使在275 ns / op下，你也更有可能在I / O上被阻塞，而不是在時間解析上被CPU阻塞。）

一般演算法很慢，因為它必須處理更多的案例。你的演算法可以更快，因為你更瞭解你的問題。但是程式碼與您需要的密切關係更緊密。如果時間格式發生變化，更新更加困難。

優化是專業化的，專用程式碼比通用程式碼更易於改變。

對於大多數情況，標準函式庫實現需要「足夠快」。如果你有更高的效能需求，你可能需要專門的實現。

定期進行配置檔案以確保追蹤系統的效能特徵，並準備隨著流量變化重新優化。瞭解你的系統的極限，並有好的指標，讓你預測什麼時候你會達到這些限制。

當你的應用程式的使用發生更改時，不同的部分可能會成為熱點。重溫先前的優化並決定它們是否仍然值得，並在可能的情況下恢復為更易讀的程式碼。我有一個系統，我使用一組複雜的mmap優化了啟動時間，反映了不安全性。一旦我們改變了系統的部署方式，這個程式碼就不再需要了，我用更可讀的常規檔案操作取代了它。

優化工作流程摘要
所有優化都應遵循以下步驟：

1. 確定你的表現目標，並確認你沒有達到他們的目標
2. 配置檔案來識別要改進的區域。
3. 這可以是CPU，堆分配或goroutine阻塞。
4. 基準來確定您的解決方案使用內建效能測試(benchmarks)框架提供的加速<http://golang.org/pkg/testing/>
5. 確保您在目標作業系統和體系結構上進行正確的效能測試(benchmarks)。
6. 之後再次進行配置以驗證問題已消失
7. 使用<https://godoc.org/golang.org/x/perf/benchstat>或<https://github.com/codahale/tinystat>來驗證一組時間「充分」不同，以便優化值得新增程式碼複雜性。
8. 使用<https://github.com/tsenart/vegeta>負載測試http服務（+其他花哨的：k6，fortio，...）
9. 確保你的延遲數字是有意義的
10. 第一步很重要。它會告訴您何時何地開始優化。更重要的是，它還會告訴你何時停止。幾乎所有優化都會增加程式碼的複雜性以換取速度。而且你總是可以更快地撰寫程式碼。這是一個平衡的行為。

## 工具

### 介紹性分析

一般適用於原始碼的技術

1. 介紹pprof
    - Go工具pprof(<https://github.com/google/pprof>)
1. 撰寫和執行(微)基準
    - 簡介，將hot code提取到基準，優化基準，配置檔案。
    - -cpuprofile/-memprofile/-benchmem
    - 0.5 ns/op意味著它被優化了 ->如何避免
    - 撰寫好的效能測試(benchmarks)的技巧(刪除不必要的工作，但增加基準)
1. 如何讀取它的pprof輸出
1. 顯示的執行系統有哪些不同的部分
1. 巨集觀基準(生產剖析)
    - net/HTTP/pprof
1. 使用-base檢視差異
1. 記憶體選項：-inuse_space，-inuse_objects，-alloc_space，-alloc_objects
1. 生產分析; localhost + ssh隧道，auth標頭檔案，使用curl。

## 追蹤

- 一些更有趣的/先進的工具
- /x/perf中的其他工具
- perf（perf2pprof）
- 英特爾vtune/amd codexl/instruments
<https://godoc.org/github.com/aclements/go-perf>

## 垃圾回收機制 (Garbage Collection)

你必須為超過一次的**記憶體配置**(memory allocation)付出成本。第一次當然是你進行初始化配置記憶體的時候，但是，你肯定也要在每次執行**垃圾回收機制**(GC)執行時付出代價。

> Reduce/Reuse/Recycle.
> -- <cite>@bboreham</cite>

- 堆疊與堆分配
- 什麼導致堆分配？
- 瞭解逃逸分析(和當前的限制)
- /debug/pprof/heap和-base
- API設計限制分配：允許傳入緩衝區，因此呼叫者可以重用而不是強制分配
- 你甚至可以在掃描時仔細修改切片
- 減少指標以減少 GC 掃描時間
  - 減少使用 `[]*Struct` (pointer-free slices)
  - 減少使用 `map[*key]` 或 `*value` (maps with both pointer-free keys and values)
- GOGC
- 緩衝區重用(sync.Pool vs或透過go-slab等自訂)
- 切片與偏移量：當GC執行時指標寫入需要writebarrier：<https://github.com/golang/go/commit/b85433975aedc2be2971093b6bbb0a7dc264c8fd>
- 使用錯誤變數而不是 `errors.New()` / `fmt.Errorf()` 在呼叫端（效能或風格？介面需要指標，所以它轉義為 heap）
- 使用結構化的錯誤來減少分配（傳遞結構值），在錯誤列印時建立字串
- size classes
- beware pinning larger allocation with smaller substrings or slices

## 執行環境和編譯器 (Runtime and compiler)

- 透過介面呼叫的成本(在CPU級別上的間接呼叫)
- runtime.convT2E/runtime.convT2I
- 型別斷言與型別切換
- 延緩
- 用於整數，字串的特殊對映實現
  - byte/uint16的對映未優化; 改用切片。
  - 你可以使用math.Float{32,64}{from,}bits優化float64-optimized ，但要注意浮動平等問題
  - <https://github.com/dgryski/go-gk/blob/master/exact.go> 據說快100倍; 需要效能測試(benchmarks)
- 邊界檢查消除
- []位元組<->字串副本，Map優化
- 雙值的range將複製一個數組，使用sclice替代：
  - <https://play.golang.org/p/4b181zkB1O>
  - <https://github.com/mdempsky/rangerdanger>
- 儘可能使用字串連線而不是fmt.Sprintf; 執行時為它已經優化了例程

## Unsafe

- 它所有的危險項
- `unsafe` 的常見用途
- `mmap` 資料檔案
  - 結構填充
  - 但並不總是足夠快以證明覆雜性/安全成本
  - 但是「off-heap」，所以被gc忽略（但是沒有指標的slice）
- 快速反序列化
- `string` <-> `slice` 轉換，`[]byte` <-> `[]uint32`，...
- `int` 到 `bool` 是不安全的 `hack` (但 `!= 0` 是可以的)
- 填充 (padding)：
  - <https://dave.cheney.net/2015/10/09/padding-is-hard>
  - <http://www.catb.org/esr/structure-packing/#_go_and_rust>
  - <https://golang.org/ref/spec#Size_and_alignment_guarantees>
  - <https://github.com/dominikh/go-tools> 結構佈局，結構佈局優化
  - 透過Offsetof對結構佈局進行編碼以發現unsafe和asm破損

## 與標準函式庫共同陷阱

- `time.After()` 洩漏，直到它被觸發
- 重用HTTP連線...
- `rand.Int()` 和朋友是 1) 互斥體保護 和 2) 建立昂貴
- 考慮交替隨機數產生(`go-pcgr`, `xorshift`)
- `binary.Read` 和 `binary.Write` 使用反射並且很慢; 手動做
- 如果可能，請使用 `strconv` 而不是 `fmt`
- ....

## 替代實現

- 標準函式庫軟體套件的普遍替代品：
  - encoding/json -> ffjson
  - net/http -> fasthttp(但不相容的API)
  - regexp -> ragel(或其他正則表示式包)
- 序列化
  - encoding/gob - > <https://github.com/alecthomas/go_serialization_benchmarks>
  - protobuf - > <https://github.com/gogo/protobuf>
  - 所有格式都有權衡：選擇一種符合你需要的編碼空間，解碼速度，語言/工具相容性......
- database/sql - > jackx/pgx，...
- gccgo
- container/list：使用切片（幾乎總是）

## cgo

> cgo is not go
> -- <cite>Rob Pike</cite>

- `cgo` 呼叫的效能特徵
- 降低成本的技巧：batching
- Go 和 C 之間傳遞指標的規則
- syso files (race detector, dev.boringssl)

## 進階技術

特定於執行程式碼的體系結構的技術

- CPU 快取介紹
  - 效能的懸崖
  - 圍繞快取行建構直覺：大小，填充，對齊
  - 共享假
  - 真正的共享 ->分片
  - OS工具來檢視快取未命中
  - Mao與切片
  - SOA vs AOS佈局
  - 減少指標追逐
- 分支預測
  - 從內部迴圈中刪除分支：

    if a { for { } } else { for { } }
    代替
    for { if a { } else { } }

    避免

    if i % 2 == 0 {
        evens++
    } else {
        odds++
    }

    counts[i & 1] ++

    並不總是更快，但通常更難以閱讀

    TODO：ASCII類別計數示例和基準

- 排序資料可以透過快取區域性性和分支預測來幫助提高效能，即使考慮到排序所花費的時間
- 函式呼叫開銷
- 關於Jeff Dean的2002年數字(加上更新)的評論
  - cpus變得更快了，但是記憶體沒有跟上

TODO: little comment about code-aligment free optimization (or unoptimization)

## 併發 (Concurrency)

- 找出哪些部分可以並行完成，哪部分必須是順序的
- goroutines很便宜，但不免費。
- 優化多執行緒程式碼
  - false-sharing -> pad to cache-line size
  - true sharing -> sharding
- 與上一節關於快取和虛假/真實共享重疊
- 延遲同步; 它很貴，所以複製工作可能會更便宜
- 你可以控制的東西：worker的數量，批量大小

你需要一個互斥體來保護共享的可變狀態。如果你有很多的互斥量爭用，你需要減少共享，或者減少mutable。減少共享的兩種方法是1）分割鎖或2）獨立處理，然後合併。為了減少mutable：好吧，讓你的資料結構是隻讀的。你還可以透過減少關鍵部分來縮短資料共享的時間 - 儘可能少地鎖定鎖定。有時候RWMutex就足夠了，但是請注意，它們比較慢，但是它們允許多個讀者進入。

如果你正在分解鎖，請注意共享快取行。您需要填充以避免快取行擁有權在處理器之間彈跳。

var stripe [8]struct{ sync.Mutex; _ [7]uint64 } //互斥量為64位; 填充填充快取行的其餘部分

## 組件 (Assembly)

- 關於為Go撰寫彙編程式碼
- 編譯器改進; bar很高
- 儘可能少地替換以產生影響
- 很好的理由：SIMD指令或者Go和編譯器可以提供的其他東西
- 非常重要的基準：改進可能是巨大的(高速公路的10倍)零(小點)，或甚至更慢(不內聯)
- 用新版本重新標記以檢視是否可以刪除程式碼
- TODO：連結到1.11補丁刪除彙編程式碼
- 總是有純粹的Go版本(noasm build tag)：測試，arm，gccgo
- 簡要介紹語法
- 呼叫的約定
- 使用不受asm支援的操作碼
- 關於為什麼內聯很難
- 使這更容易工具：asmfmt，peachpy，c2goasm，...

## 優化整個服務 (Optimizing an entire service)

大多數情況下，你不會看到一個CPU限制的例程。這是一個簡單的例子。如果你有優化服務，則需要檢視整個系統。監測。指標。隨著時間的推移記錄很多事情，這樣你可以看到它們變得更糟，所以你可以看到你的更改對生產的影響。

tip.golang.org/doc/diagnostics.html

- 系統設計參考：SRE Book，實用的分散式系統設計
- 額外的工具：更多日誌記錄+分析
- 兩條基本規則：加速緩慢的事情或減少頻率。
- 分散式追蹤以追蹤更高級別的瓶頸
- 用於查詢單個伺服器而不是批量查詢模式
- 你的效能問題可能不是你的程式碼，但是你仍然需要解決它們

## Tooling

### Introductory Profiling

This is a quick cheat-sheet for using the pprof tooling.  There are plenty of other guides available on this.
Check out https://github.com/davecheney/high-performance-go-workshop.

TODO(dgryski): videos?

1. Introduction to pprof
   - go tool pprof (and <https://github.com/google/pprof>)
1. Writing and running (micro)benchmarks
   - small, like unit tests
   - profile, extract hot code to benchmark, optimize benchmark, profile.
   - -cpuprofile / -memprofile / -benchmem
   - 0.5 ns/op means it was optimized away -> how to avoid
   - tips for writing good microbenchmarks (remove unnecessary work, but add baselines)
1. How to read it pprof output
1. What are the different pieces of the runtime that show up
  - malloc, gc workers
  - runtime.\_ExternalCode
1. Macro-benchmarks (Profiling in production)
   - larger, like end-to-end tests
   - net/http/pprof, debug muxer
   - because it's sampling, hitting 10 servers at 100hz is the same as hitting 1 server at 1000hz
1. Using -base to look at differences
1. Memory options: -inuse_space, -inuse_objects, -alloc_space, -alloc_objects
1. Profiling in production; localhost+ssh tunnels, auth headers, using curl.
1. How to read flame graphs

### Tracer

### Look at some more interesting/advanced tooling

- other tooling in /x/perf
- perf (perf2pprof)
- intel vtune / amd codexl / apple instruments
- https://godoc.org/github.com/aclements/go-perf

## 附錄：實作研究論文 (Appendix: Implementing Research Papers)

實作論文的提示：( For `algorithm` read also `data structure`）

- 不要。從明顯的解決方案和合理的資料結構開始。

「現代」演算法往往具有較低的理論複雜性，但具有較高的常數因子和很多實作複雜性。其中一個經典例子是斐波那契堆。他們很難得到正確的，並有一個巨大的不變因素。已經發表了多篇論文，比較了不同工作負載下堆的實現方式，總體而言，4或8元的隱含堆總是排在前列。即使在Fibonacci堆應該更快（由於O（1）「減少鍵」）的情況下，使用Dijkstra的深度優先搜尋演算法的實驗表明，當他們使用直接堆去除和加法時，它的速度更快。

類似地，對比更復雜的紅黑或AVL樹也可以找到對照或者跳過列表。在現代硬體上，「較慢」的演算法可能足夠快，甚至更快。

> 最快的演算法經常可以被幾乎一樣快速且容易理解的演算法取代。
>
> -- <cite>Douglas W. Jones, University of Iowa</cite>

增加的複雜性必須足以使得回報實際上值得。另一個例子是快取驅逐演算法。不同的演算法可以具有高得多的複雜度，僅命中率的小改進。當然，您可能無法在測試之前進行測試，直到您有一個可行的實作並將其整合到您的程式中。

有時候這篇論文會有圖表，但很像只發布正面結果的趨勢，但這些傾向往往會偏向於表示新演算法的優點。

- 選擇正確的紙張。
- 尋找他們的演算法聲稱擊敗和實作的論文。

通常，早期的論文會更容易理解，並且必須具有更簡單的演算法。

並非所有的檔案都很好。

檢視論文寫入的上下文。確定有關硬體的假設：磁碟空間，記憶體使用情況等。一些較舊的論文在70年代或80年代進行了合理的不同折衷，但不一定適用於您的使用案例。例如，他們認為什麼是「合理的」記憶體與磁碟使用的權衡。記憶體大小現在增加了數量級，並且SSD改變了使用磁碟的延遲懲罰。同樣，一些流媒體演算法是為路由器硬體而設計的，這可能會使轉換成軟體變得非常痛苦。

確保演算法對資料保持的假設。

這將需要一些挖掘。你可能不想實現你找到的第一篇論文。

- 確保你瞭解演算法。這聽起來很明顯，但是否則無法進行除錯。

 <https://blizzard.cs.uwaterloo.ca/keshav/home/Papers/data/07/paper-reading.pdf>

一個良好的理解可能會讓你從論文中提取關鍵的想法，並且可能將這個想法應用於你的問題，這可能比重新實現整個事情更簡單。

- 資料結構或演算法的原始檔案並不總是最好的。後來的論文可能會有更好的解釋。

- 一些論文發佈了可以與之比較的參考原始碼，但是

    1. 學術程式碼幾乎普遍可怕
    2. 謹防許可限制（僅限「研究目的」）
    3. 提防錯誤; 邊緣情況，錯誤檢查，效能等。

還要注意GitHub上的其他實現：它們可能與您的bug相同（或不同）。

有關此主題的其他資源：

- <https://www.youtube.com/watch?v=8eRx5Wo3xYA>
- <http://codecapsule.com/2012/01/18/how-to-implement-a-paper/>
